{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "KMeans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl4SWCaeIiMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rabg-syIbOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import randint, uniform\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn5WX4MTIzCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e836a601-50b0-455f-9008-47c0db1aef6d"
      },
      "source": [
        "#load the HTRU_2 dataset and save true class labels as separate array\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1y2Ypp16D8hE959IrKCADOvpSHz4Tu2Mz' in parents and trashed=false\"}).GetList()\n",
        "downloaded = drive.CreateFile({'id':file_list[0]['id']})   \n",
        "downloaded.GetContentFile(file_list[0]['originalFilename'])  \n",
        "data_htru=pd.read_csv(file_list[0]['originalFilename'],header = None)\n",
        "data_htru.insert(0, 'id', data_htru.index)\n",
        "data_htru.columns=[str(column) for column in data_htru.columns.values]\n",
        "true_htru=data_htru.iloc[:,-1]\n",
        "data_htru=data_htru.drop(columns='8')\n",
        "data_htru.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>140.562500</td>\n",
              "      <td>55.683782</td>\n",
              "      <td>-0.234571</td>\n",
              "      <td>-0.699648</td>\n",
              "      <td>3.199833</td>\n",
              "      <td>19.110426</td>\n",
              "      <td>7.975532</td>\n",
              "      <td>74.242225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>102.507812</td>\n",
              "      <td>58.882430</td>\n",
              "      <td>0.465318</td>\n",
              "      <td>-0.515088</td>\n",
              "      <td>1.677258</td>\n",
              "      <td>14.860146</td>\n",
              "      <td>10.576487</td>\n",
              "      <td>127.393580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>103.015625</td>\n",
              "      <td>39.341649</td>\n",
              "      <td>0.323328</td>\n",
              "      <td>1.051164</td>\n",
              "      <td>3.121237</td>\n",
              "      <td>21.744669</td>\n",
              "      <td>7.735822</td>\n",
              "      <td>63.171909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>136.750000</td>\n",
              "      <td>57.178449</td>\n",
              "      <td>-0.068415</td>\n",
              "      <td>-0.636238</td>\n",
              "      <td>3.642977</td>\n",
              "      <td>20.959280</td>\n",
              "      <td>6.896499</td>\n",
              "      <td>53.593661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>88.726562</td>\n",
              "      <td>40.672225</td>\n",
              "      <td>0.600866</td>\n",
              "      <td>1.123492</td>\n",
              "      <td>1.178930</td>\n",
              "      <td>11.468720</td>\n",
              "      <td>14.269573</td>\n",
              "      <td>252.567306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id           0          1  ...          5          6           7\n",
              "0   0  140.562500  55.683782  ...  19.110426   7.975532   74.242225\n",
              "1   1  102.507812  58.882430  ...  14.860146  10.576487  127.393580\n",
              "2   2  103.015625  39.341649  ...  21.744669   7.735822   63.171909\n",
              "3   3  136.750000  57.178449  ...  20.959280   6.896499   53.593661\n",
              "4   4   88.726562  40.672225  ...  11.468720  14.269573  252.567306\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxv8b9ZIbPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Kmeans:\n",
        "    def __init__(self, k, data):\n",
        "        self.k=k\n",
        "        self.original_data = data.copy()\n",
        "        \n",
        "        # initialize k centroids with mock values\n",
        "        self.mock_centroids=pd.DataFrame(\n",
        "            np.full((self.k,self.original_data.shape[1]),-1.0),\n",
        "            columns=self.original_data.columns.values)\n",
        "        self.mock_centroids['id']=np.arange(1,self.k+1)\n",
        "        \n",
        "        # assign points to mock clusters\n",
        "        self.original_data['k']=-1\n",
        "        self.original_data['distance']=-1\n",
        "        \n",
        "        # add suffixes to columns\n",
        "        self.original_data.columns += '_d'\n",
        "        self.mock_centroids.columns += '_c'\n",
        "        \n",
        "        #create key to allow for join to get cartesian product\n",
        "        self.original_data['key']=1\n",
        "        self.mock_centroids['key']=1\n",
        "        \n",
        "        # copy dataframes\n",
        "        self.data=self.original_data.copy()\n",
        "        self.centroids = self.mock_centroids.copy()\n",
        "        \n",
        "    \n",
        "    def assign_centroids(self, dataframe, centroids, i):\n",
        "        \n",
        "        # compute euclidan distance for all combinations       \n",
        "        df = dataframe.merge(centroids, how='outer')\n",
        "\n",
        "        df['distance_d'] = np.linalg.norm(\n",
        "            df[self.data.columns.values.tolist()[1:-3]].values\n",
        "            -df[self.centroids.columns.values.tolist()[1:-1]].values, axis=1)\n",
        "\n",
        "        # assign centroid that is closest to the record\n",
        "        df=df.sort_values(['id_d','distance_d']).drop_duplicates(['id_d'],keep='first')\n",
        "        df.reset_index(inplace=True)\n",
        "        df['k_d']=df['id_c']\n",
        "        df=df[self.data.columns.values.tolist()].copy()\n",
        "        return df\n",
        "    \n",
        "    \n",
        "    def calculate_centroids(self):\n",
        "        # calculate position of centroids\n",
        "        cols=self.centroids.columns\n",
        "        self.centroids=self.data.drop(['id_d','distance_d'], axis=1).groupby(['k_d']).agg(['mean'])\n",
        "        self.centroids.reset_index(inplace=True) \n",
        "        self.centroids.columns=cols\n",
        "    \n",
        "    \n",
        "    def initialize_clusters(self, method='forgy'):\n",
        "        '''\n",
        "        Names of methods taken from article:\n",
        "        A comparative study of efficient initialization methods for the k-means\n",
        "        clustering algorithm\n",
        "        \n",
        "        METHODS:\n",
        "        \n",
        "        macqueen - randomly selected points. k distinct cases of the data are \n",
        "        randomly selected to be the initial centres. The second method chooses \n",
        "        the centers randomly from the data points. The rationale behind this \n",
        "        method is that random selection is likely to pick points from dense \n",
        "        regions,i.e. points that are good candidates to be centers. \n",
        "        \n",
        "        forgy- assigns each point to one of theKclusters uniformly at random. \n",
        "        The centers are then given by the centroids of these initial clusters.\n",
        "        \n",
        "        kmpp - random farthest points, or k-means++. \n",
        "        The first centre is selected as a random case from the dataset. \n",
        "        The 2nd centre is selected also randomly, but the probability of \n",
        "        selection of a case is proportional to the distance (square euclidean) \n",
        "        of it to that (1st) centre. The 3rd centre is selected also randomly \n",
        "        with the probability of selection proportional to the distance of a case\n",
        "        to the nearest of those two centres, - and so on. \n",
        "        (Source: Arthur, D., Vassilvitskii, S.. K-means++: the advantages of \n",
        "        careful seeding. //Proceedings of the 18th annual ACM-SIAM symposium on \n",
        "        Discrete algorithms. 2007., 1027–1035.)\n",
        "        \n",
        "        robin - The ROBIN approach to seed selection is essentially tied to the \n",
        "        concept of avoiding outliers as seeds. For this ROBIN first computes \n",
        "        the degree to which a point is an outlier, which in turn must consider \n",
        "        the local density of the neighboring points. Outliers are those points \n",
        "        whose density is very different compared to neighbor densities. \n",
        "        In essence the local outlier measure automatically takes into account \n",
        "        variable density regions and variable size clusters. The key aim here \n",
        "        is to avoid the computation of outlier measure for each point in \n",
        "        the dataset, which would yield a worst case method, but rather the \n",
        "        challenge is in keeping the complexity very close to linear in n.\n",
        "        (Source: Robust partitional clustering by outlier and density \n",
        "        insensitive seeding)\n",
        "        '''\n",
        "        #reset data and centroids\n",
        "        self.data=self.original_data.copy()\n",
        "        self.centroids=self.mock_centroids.copy()\n",
        "        \n",
        "        if method=='macqueen':\n",
        "            \n",
        "            # centroids as random data points\n",
        "            self.data.sample(n=self.k)\n",
        "            for i in range(0, self.k):\n",
        "                for col in self.centroids.columns.values.tolist()[1:-1]:\n",
        "                    self.centroids.at[i, col]=self.data.at[i, col[:-1]+'d']\n",
        "                \n",
        "        \n",
        "        if method == 'forgy':\n",
        "            # assign points to random clusters (no cluster can be empty)\n",
        "            while any(init_k not in self.data['k_d'].values \n",
        "                      for init_k in range(1,self.k+1)): \n",
        "                self.data['k_d']=self.data['k_d'].apply(\n",
        "                    lambda x: randint(1,self.k))\n",
        "                \n",
        "            #calculate initial centroids       \n",
        "            self.calculate_centroids()\n",
        "                \n",
        "        if method == \"kmpp\":\n",
        "            df = self.data.copy()\n",
        "            for i in range(0,self.k):\n",
        "                if i == 0:\n",
        "                    # Take one center c1, chosen uniformly at random from X .\n",
        "                    initial=randint(0,self.k)\n",
        "                    for col in self.centroids.columns.values.tolist()[1:-1]:\n",
        "                        self.centroids.at[i,col] = df.at[initial,col[:-1]+'d']      \n",
        "                            \n",
        "                else:\n",
        "                    # Take a new center ci choosing x ∈ X with probability \n",
        "                    # D(x) / sum x∈X D(x)\n",
        "                    df=self.assign_centroids(df, self.centroids.iloc[:i+1,:], i)\n",
        "                    \n",
        "                    # calculate square distance\n",
        "                    df['distance_d']=df['distance_d']**2\n",
        "                    sum_of_distance=df['distance_d'].sum()\n",
        "                    df['probability']=df['distance_d']/sum_of_distance\n",
        "                    \n",
        "                    # choose  new centroid with probability \n",
        "                    # D^2(x) / sum  x∈X D^2(x)\n",
        "                    select_random=uniform(0,1)\n",
        "                    cumulant=0\n",
        "                    for j in range(df.shape[0]):\n",
        "                        cumulant = cumulant + df.at[j, 'probability']\n",
        "                        if select_random <= cumulant:\n",
        "                            for col in self.centroids.columns.values.tolist()[1:-1]:\n",
        "                                self.centroids.at[i, col] = df.at[j,col[:-1]+'d']\n",
        "                            break\n",
        "\n",
        "            \n",
        "        if method=='robin':\n",
        "            df=self.data.copy()\n",
        "            clf = LocalOutlierFactor(n_neighbors=3, novelty=True)\n",
        "            \n",
        "            for i in range(0,self.k):\n",
        "                if i==0:\n",
        "                    r=self.data.sample(n=1)\n",
        "                    df['robin_dist']= np.linalg.norm(\n",
        "                        df[self.data.columns.values.tolist()[1:-3]].values\n",
        "                        -r[self.data.columns.values.tolist()[1:-3]].values,axis=1)\n",
        "                    df_sorted=df.sort_values('robin_dist', ascending=False)\n",
        "                    df_sorted.drop(columns=['k_d','distance_d','key','robin_dist'], inplace=True)\n",
        "                    df_sorted.reset_index(drop=True,inplace=True) \n",
        "                else:\n",
        "                    df=self.assign_centroids(df, self.centroids.iloc[:i+1,:], i)\n",
        "                    df_sorted=df.sort_values('distance_d', ascending=False)\n",
        "                    df_sorted.drop(columns=['k_d','distance_d','key'], inplace=True)\n",
        "                    df_sorted.reset_index(drop=True,inplace=True)\n",
        "                      \n",
        "                for index, row in df_sorted.iloc[:,1:].iterrows():\n",
        "                    row=pd.DataFrame(row).T.values\n",
        "                    clf.fit(df_sorted.iloc[:,1:].drop(index=index))\n",
        "                    LOF=clf.predict(row)\n",
        "                    if LOF[0]==1:\n",
        "                        for col in self.centroids.columns.values.tolist()[1:-1]:\n",
        "                            self.centroids.at[i,col] = df_sorted.at[index,col[:-1]+'d']\n",
        "                        break\n",
        "\n",
        "                               \n",
        "    def plot_clusters(self, dataframe, centroids, i):\n",
        "\n",
        "        #select subset of dataframe with features\n",
        "        X = dataframe.copy().drop(columns=['id_d','k_d','distance_d','key'])\n",
        "        y = dataframe['k_d'].copy().values\n",
        "        \n",
        "        X_c = centroids.copy().drop(columns=['id_c']).values\n",
        "        y_c = centroids['id_c'].copy().values\n",
        "        \n",
        "        if X.shape[1] == 2:\n",
        "            method = 'Plot'\n",
        "            X_reduced_pca = X.values\n",
        "        else:\n",
        "            method = 'PCA'\n",
        "            # calculate PCA Implementation of dim reducition\n",
        "            X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)\n",
        "\n",
        "        #plotting\n",
        "        f, (ax1) = plt.subplots(1, 1, figsize=(6,6))\n",
        "        f.suptitle('Iteration ' + str(i), fontsize=14)\n",
        "\n",
        "        # scatter plot\n",
        "        ax1.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], \n",
        "                    c=y, cmap='rainbow', linewidths=4)\n",
        "        ax1.scatter(X_c[:,0], X_c[:,1], c=y_c, marker='x', \n",
        "                    s=150, cmap='rainbow', linewidths=10)\n",
        "        ax1.set_title(method, fontsize=14)\n",
        "        ax1.grid(True)\n",
        "\n",
        "        plt.show()\n",
        "        \n",
        "    \n",
        "    def Lloyd(self, make_plots = False):\n",
        "        converged=False\n",
        "        i=0\n",
        "        while not converged:\n",
        "            if make_plots:\n",
        "              self.plot_clusters(self.data, self.centroids, i)\n",
        "            \n",
        "            i+=1\n",
        "            clusters_before = self.data['k_d'].values\n",
        "            self.data=self.assign_centroids(self.data, self.centroids, i)\n",
        "            clusters_after = self.data['k_d'].values\n",
        "            \n",
        "            #check if algorithm converged\n",
        "            if all(c_before == c_after for c_before, c_after \n",
        "                   in zip(clusters_before,clusters_after)):\n",
        "                converged = True\n",
        "            \n",
        "            # update centroids\n",
        "            self.calculate_centroids()\n",
        "            \n",
        "            #checking if a cluster disapeared in the process (erronous behaviour)\n",
        "            # TODO: add exception\n",
        "            if len(self.data.k_d.unique()) != self.k:\n",
        "                print('Cluster disapeared, break. Temporary solution.')\n",
        "                raise Exception\n",
        "    \n",
        "    def MacQueen(self, make_plots = False):\n",
        "        converged=False\n",
        "        i=0\n",
        "        while not converged:\n",
        "            print('ITERATION', i, datetime.now())\n",
        "            if make_plots:\n",
        "                self.plot_clusters(self.data, self.centroids, i)\n",
        "            \n",
        "            i+=1            \n",
        "            clusters_before = self.data['k_d'].values\n",
        "            for index,row in self.data.iterrows():\n",
        "                row = pd.DataFrame(row).T\n",
        "                # assign point to centroid\n",
        "                self.data.iloc[index,:]=self.assign_centroids(row, self.centroids, i).values[0]\n",
        "                # TODO: recalculate centroids if point changed cluster \n",
        "\n",
        "            # update centroids\n",
        "            self.calculate_centroids()\n",
        "            clusters_after = self.data['k_d'].values\n",
        "            \n",
        "            #check if algorithm converged\n",
        "            if all(c_before == c_after for c_before, c_after in zip(clusters_before,clusters_after)):\n",
        "                converged = True\n",
        "                \n",
        "            #checking if a cluster disapeared in the process (erronous behaviour)\n",
        "            # TODO: add exception\n",
        "            if len(self.data.k_d.unique()) != self.k:\n",
        "                print('Cluster disapeared, break. This is a temporary solution.')\n",
        "                raise Exception\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKtexYjkIbPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ex4 = Kmeans(2,data_htru)\n",
        "ex4.initialize_clusters(method='forgy')\n",
        "ex4.Lloyd(make_plots=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Y74S4cmlIbPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "7d593a07-acd9-4b2d-9bb9-511d8343597b"
      },
      "source": [
        "ex4 = Kmeans(3,data_htru)\n",
        "ex4.initialize_clusters(method='macqueen')\n",
        "ex4.MacQueen()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ITERATION 0 2020-03-18 19:03:56.315988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2fe6fc8d2dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mex4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_htru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mex4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macqueen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mex4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMacQueen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-248edc4303fc>\u001b[0m in \u001b[0;36mMacQueen\u001b[0;34m(self, make_plots)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# assign point to centroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;31m# TODO: recalculate centroids if point changed cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-248edc4303fc>\u001b[0m in \u001b[0;36massign_centroids\u001b[0;34m(self, dataframe, centroids, i)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k_d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3005\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3603\u001b[0m         new_data = self._data.take(\n\u001b[0;32m-> 3604\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3605\u001b[0m         )\n\u001b[1;32m   3606\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         return self.reindex_indexer(\n\u001b[0;32m-> 1397\u001b[0;31m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m         )\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             new_blocks = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m                             \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m                             \u001b[0mfill_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m                         )\n\u001b[1;32m   1359\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         new_values = algos.take_nd(\n\u001b[0;32m-> 1313\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m         )\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     func = _get_take_nd_function(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n\u001b[1;32m   1721\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_take_nd_function\u001b[0;34m(ndim, arr_dtype, out_dtype, axis, mask_info)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_take_nd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_1d_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_name_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0;31m# provides dtype.name.__get__, documented as returning a \"bit name\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58HPPLI8BVah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}