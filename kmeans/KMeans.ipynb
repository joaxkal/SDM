{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kmeans_proby.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI0zteqvqYTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxuQ1i_cqfH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import randint, uniform\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "from datetime import datetime\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-pK8ePJni9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Kmeans:\n",
        "\n",
        "\n",
        "    def __init__(self, k, points):\n",
        "      self.k=k\n",
        "\n",
        "      self.points = points\n",
        "      self.centroids=np.full(shape=(self.k,self.points.shape[1]), fill_value=-1, dtype=np.float64)\n",
        "\n",
        "      # auxiliary columns: point_id, assigned cluster, distance to cluster\n",
        "      points_aux=np.full(shape=(self.points.shape[0], 3),fill_value=-1)\n",
        "      points_aux[:, 0]=np.arange(start=0, stop=self.points.shape[0])\n",
        "      self.points=np.append(self.points, points_aux, axis=1)\n",
        "      \n",
        "      # auxiliary columns: centroid id, counts of assigned points\n",
        "      centroids_aux=np.full(shape=(self.k, 2),fill_value=-1)\n",
        "      centroids_aux[:, 0]=np.arange(start=0, stop=self.k)\n",
        "      self.centroids=np.append(self.centroids,centroids_aux,axis=1 )\n",
        "\n",
        "\n",
        "    # method used in Lloyd and initialization \n",
        "    def calculate_all_centroids(self):\n",
        "      for k in range(self.k):\n",
        "        self.centroids[k,:-2] = self.points[self.points[:,-2]==k][:, :-3].mean(axis=0)\n",
        "        self.centroids[k,-1] = len(self.points[self.points[:,-2]==k][:, -3])\n",
        "    \n",
        "\n",
        "    def initialize_clusters(self, method='forgy'):\n",
        "      self.points[:,-2]=-1\n",
        "      if method=='forgy':\n",
        "        while any(k not in self.points[:,-2] for k in range(0,self.k)):\n",
        "          self.points[:,-2]=np.random.randint(0, self.k, self.points.shape[0])\n",
        "      self.calculate_all_centroids()\n",
        "\n",
        "\n",
        "    # method used in MacQueen - recalculates old and new centroid\n",
        "    def calculate_two_centroids(self, point, min_cen):\n",
        "      old = np.where(self.centroids[:,-2]==point[-2])[0]\n",
        "                            \n",
        "      #update old centroid\n",
        "      self.centroids[old,:-2] = self.centroids[old,:-2] * self.centroids[old,-1] - point[:-3]                \n",
        "      self.centroids[old,-1] = self.centroids[old,-1] - 1\n",
        "      self.centroids[old,:-2] = self.centroids[old,:-2] / self.centroids[old,-1]\n",
        "\n",
        "      #update new centroid\n",
        "      min_cen[:-2] = min_cen[:-2] * min_cen[-1] + point[:-3]\n",
        "      min_cen[-1] = min_cen[-1] + 1\n",
        "      min_cen[:-2] = min_cen[:-2] / min_cen[-1]\n",
        "      return min_cen\n",
        "\n",
        "\n",
        "    def assign_clusters(self, macqueen=False):\n",
        "      for point in self.points:\n",
        "        min=np.inf\n",
        "        min_cen=point[-2]\n",
        "        for cen in self.centroids:\n",
        "            diff = point[:-3] - cen[:-2]\n",
        "            dist = np.inner(diff,diff)\n",
        "            if dist < min:\n",
        "                min = dist\n",
        "                min_cen = cen\n",
        "\n",
        "        if min_cen[-2]!=point[-2]:\n",
        "          if macqueen==True:\n",
        "            min_cen = self.calculate_two_centroids(point, min_cen)\n",
        "          #update centroid assignment if changed\n",
        "          point[-2]=min_cen[-2]\n",
        "          point[-1]=min \n",
        "\n",
        "\n",
        "\n",
        "    def plot_clusters(self, points, centroids, i):\n",
        "        #select subset of dataframe with features\n",
        "        X = points[:,:-3]\n",
        "        y = points[:,-2]\n",
        "       \n",
        "        X_c = centroids[:,:-2]\n",
        "        y_c = centroids[:,-2]\n",
        "       \n",
        "        if X.shape[1] == 2:\n",
        "            method = 'Plot'\n",
        "            X_reduced_pca = X\n",
        "            X_c_reduced_pca = X_c\n",
        "        else:\n",
        "            method = 'PCA'\n",
        "            # calculate PCA Implementation of dim reducition\n",
        "            pca=PCA(n_components=2, random_state=42)\n",
        "            pca.fit(X)\n",
        "            X_reduced_pca = pca.transform(X)\n",
        "            X_c_reduced_pca = pca.transform(X_c)\n",
        "\n",
        "        #plotting\n",
        "        f, (ax1) = plt.subplots(1, 1, figsize=(6,6))\n",
        "        f.suptitle('Iteration ' + str(i), fontsize=14)\n",
        "\n",
        "        # scatter plot\n",
        "        ax1.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1],\n",
        "                    c=y, cmap='rainbow', linewidths=4)\n",
        "        ax1.scatter(X_c_reduced_pca[:,0], X_c_reduced_pca[:,1],\n",
        "                    c=y_c, marker='x',\n",
        "                    s=150, cmap='rainbow', linewidths=10)\n",
        "        ax1.set_title(method, fontsize=14)\n",
        "        ax1.grid(True)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def MacQueen(self, make_plots=False):\n",
        "        i=0\n",
        "        while True:\n",
        "          print('ITERATION', i, datetime.now())\n",
        "          if make_plots:\n",
        "            self.plot_clusters(self.points, self.centroids, i)   \n",
        "\n",
        "          clusters_before = self.points[:,-2].copy()\n",
        "          self.assign_clusters(macqueen=True)\n",
        "          clusters_after = self.points[:,-2].copy()\n",
        "          #check if algorithm converged\n",
        "          if not any(c_before != c_after for c_before, c_after in zip(clusters_before,clusters_after)):\n",
        "            break\n",
        "          #self.calculate_all_centroids()\n",
        "          i=i+1\n",
        "\n",
        "\n",
        "    def Lloyd(self, make_plots=False):\n",
        "      i=0\n",
        "      while True:\n",
        "          print('ITERATION', i, datetime.now())\n",
        "          if make_plots:\n",
        "            self.plot_clusters(self.points, self.centroids, i)         \n",
        "          clusters_before = self.points[:,-2].copy()\n",
        "          self.assign_clusters(macqueen=False)\n",
        "          clusters_after = self.points[:,-2].copy()\n",
        "          #check if algorithm converged\n",
        "          if not any(c_before != c_after for c_before, c_after in zip(clusters_before,clusters_after)):\n",
        "              break\n",
        "          self.calculate_all_centroids()\n",
        "          i=i+1\n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLP8qyzQqhRg",
        "colab_type": "code",
        "outputId": "bbe816d2-8c86-4a73-c5ba-6d801f1b879d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#load the HTRU_2 dataset and save true class labels as separate array\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1y2Ypp16D8hE959IrKCADOvpSHz4Tu2Mz' in parents and trashed=false\"}).GetList()\n",
        "for file in file_list:\n",
        "  downloaded = drive.CreateFile({'id':file['id']})   \n",
        "  downloaded.GetContentFile(file['originalFilename'])\n",
        "  print(file['originalFilename'], file['id'])\n",
        "\n",
        "data_htru_raw = np.genfromtxt('HTRU_2.csv', delimiter=',')\n",
        "data_htru=data_htru_raw[:, 0:-1].copy()  \n",
        "\n",
        "data_skin_raw=np.genfromtxt('Skin_NonSkin.txt', delimiter='\\t')\n",
        "data_skin=data_skin_raw[:, 0:-1].copy()  \n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skin_NonSkin.txt 1ZbOE3GxszqNT6iMqxkD_Fdh4y2yzm-hY\n",
            "HTRU_2.csv 1RPjRbzuf4SZ5VunY1HgQVlWfZ7dpjOTA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKaDyF3jxwn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "831771cb-5f4f-4056-aafe-9cabaa9a5912"
      },
      "source": [
        "# Own implementation testing:\n",
        "ex4=Kmeans(2, data_htru)\n",
        "ex4.initialize_clusters()\n",
        "ex4.MacQueen(make_plots=False)\n",
        "own_NMI= normalized_mutual_info_score(data_htru_raw[:,-1], ex4.points[:,-2])\n",
        "print(own_NMI)\n",
        "\n",
        "#Sklearn clustering to compare\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit_predict(data_htru)\n",
        "sklearn_NMI=normalized_mutual_info_score(data_htru_raw[:,8], kmeans)\n",
        "\n",
        "print(sklearn_NMI)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ITERATION 0 2020-03-22 12:49:52.153202\n",
            "ITERATION 1 2020-03-22 12:49:52.617683\n",
            "ITERATION 2 2020-03-22 12:49:52.802889\n",
            "ITERATION 3 2020-03-22 12:49:52.968688\n",
            "ITERATION 4 2020-03-22 12:49:53.114894\n",
            "ITERATION 5 2020-03-22 12:49:53.260394\n",
            "ITERATION 6 2020-03-22 12:49:53.394365\n",
            "ITERATION 7 2020-03-22 12:49:53.544444\n",
            "ITERATION 8 2020-03-22 12:49:53.674894\n",
            "ITERATION 9 2020-03-22 12:49:53.808721\n",
            "ITERATION 10 2020-03-22 12:49:53.937517\n",
            "ITERATION 11 2020-03-22 12:49:54.071056\n",
            "ITERATION 12 2020-03-22 12:49:54.207138\n",
            "ITERATION 13 2020-03-22 12:49:54.340502\n",
            "ITERATION 14 2020-03-22 12:49:54.473557\n",
            "ITERATION 15 2020-03-22 12:49:54.608775\n",
            "ITERATION 16 2020-03-22 12:49:54.737772\n",
            "0.02649673183252321\n",
            "0.02643778644792407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Hw1Knu6CfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1487c6d-88d0-4295-d910-f423f09cfea7"
      },
      "source": [
        "data_skin_raw[:,-1]-1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oTJrQy5Ix9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}